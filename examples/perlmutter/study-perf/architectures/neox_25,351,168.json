{
  // parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages
  // across the node boundaries )
  "pipe-parallel-size": 1,
  "model-parallel-size": 1,
  // model settings
  "num-layers": 8,
  "hidden-size": 512,
  "num-attention-heads": 8,
  "seq-length": 2048,
  "max-position-embeddings": 2048,
  "norm": "layernorm",
  "pos-emb": "rotary",
  "rotary_pct": 0.25,
  "no-weight-tying": true,
  "gpt_j_residual": true,
  "output_layer_parallelism": "column",
  "scaled-upper-triang-masked-softmax-fusion": true,
  "bias-gelu-fusion": true
}